# Adversarial Attack Visualization
Source code for the website and the project to generate adversarial examples to fool common Machine Learning models.

This is the repository for Visualizing and Comparision of Various Adversarial Attacks on user Uploaded Images using a User-Friendly interface using the DNN framework Pytorch, using popular SOTA Pretrained `TorchVision`  ModelZoo. The Following Attacks have been implemented so far and code can be found inside `GAE/attacks.py`

* Fast Gradient Sign Method, Untargeted [1]
* Fast Gradient Sign Method, Targeted [1]
* Basic Iterative Method, Untargeted [2]
* Least Likely Class Iterative Method [2]
* DeepFool, untargeted [3]
* LBFGS, targeted [4]

Coming Soon: Carlini-Wagner l2, FGSM

